1）为什么需要数据降维
不进行降维会导致数据维数灾难，训练效果变差。

2）PCA与LDA的原则
PCA：最大信息保持，保留数据方差最大的方向
LDA：最大可能的区分不同类别，保证同类别内的样本尽可能接近，不同类样本尽可能远离

3）数据维数D，类别数量C，PCA与LDA的降维的最大维数
PCA：再假设每个样本是k和特征，应该是D-1与k-1中较小的
LDA：C-1

4）何种情况下PCA优于LDA
当数据是否同一类的主要差别在于方差而不是均值的时候

5）流形学习
不是欧氏距离
相当于曲面展开后的距离。实际计算的时候是每次取一小块周围邻域内的点计算距离，最后将所有距离拼接起来。

备注：code为代码部分，目前没有整理所以结构有点乱
code
---output3:对原图进行lbp的输出图像
---data_preprocess:部分图像预处理的方法，包括均值跟lbp。lbp方法因为256维太高采用了降维至59维的uniform lbp方法
---iris.data:鸢尾花数据
---iris_tree_preprocess:导入iris.data
---lda:lda方法
---lda2:与lda相同，但是输出为sw，sb，jw三个矩阵，用来测试数据
---pca：pca方法
---read_face：读取orl数据
---test_accuracy：测试预测准确度
---untitled1：测试，内容与untitled2基本相同，后面基本不使用了
---untitled2：主要的测试
---untitled3：测试鸢尾花
---untitled4：输出lbp图像

不进行说明时测试结果均为41个数据全部进入训练。
测试结果PCA在各个情况下准确性都比较高，大约有90%的准确度。LDA表现比较差。
LDA在实际运行时经常会出现奇异矩阵的问题，尤其是进行训练的样本较少时更容易出现。主要是sw矩阵不可逆导致jw矩阵特征值计算错误
目前的lda方法在不进行任何处理时准确率只有10%-30%，取均值后有50%，lbp初始图像准确率也只有20%左右。当采用uniform lbp的方法时候计算特征值出错。
在测试鸢尾花的时候两个都比较好，都有90%左右，所以我感觉是LDA的数据预处理问题或者是41维分类对于LDA方法难度高了。